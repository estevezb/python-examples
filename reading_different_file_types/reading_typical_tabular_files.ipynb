{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For those new to Jupyter notebooks\n",
    "\n",
    "-  This is a jupyter notebook file\n",
    "- It is a format used by many data science fields for data analysis and visualization tasks\n",
    "- Useful because (a) it is easier to work with and understand than single python script files (.py) and (b) enables you to break problems down into steps, and quickly see those results in the same window\n",
    "\n",
    "## Types of Jupyter notebook cells \n",
    "(1) **Markdown** cells (Cell->Cell Type->Markdown)\n",
    "   - text, images \n",
    "   - cannot compile code you put in Markdown cells \n",
    "<br><br>\n",
    "\n",
    "(2) **Code** cells (Cell->Cell Type->Code)\n",
    "   - store and compile your code\n",
    "   - any non-code text must be formatted as a comment - begin with \"#\"\n",
    "<br><br>\n",
    "\n",
    "### Running Jupyter notebook cells \n",
    "(1) **Entire notebook**\n",
    " - Cell->Run All\n",
    "<br><br>\n",
    "\n",
    "(2) **Single code cell**\n",
    " - Click on the cell and hit Shift-Enter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to quickly read and get summary of  typical types of data files:\n",
    "- xlsx (Excel)\n",
    "- .txt (Text) \n",
    "- .csv (Comma separated)\n",
    "\n",
    "### Use cases\n",
    "-   Large file size / number of records makes it difficult and slow to use the data directly\n",
    "-   Get a quick, succinct understanding of the data layout, record count, column names, missing data\n",
    "-   You will be doing repetitive checks, counts, analyses, etc., across different columns, datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Python \"modules\" that we need.\n",
    "# Many modules are standard, such that \"import\" is sufficient.\n",
    "# Others require first installing the package!\n",
    "# We will use the Python \"matplotlib\" plotting module here.\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import chardet # automatically decodes the file format to handle character formatting differences in some file types\n",
    "\n",
    "import pandas as pd # use to to work on data as dataframe\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt # if you want to make plots\n",
    "\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "xls = pd.ExcelFile(latest_file)\n",
    "\n",
    "# Get the sheet names\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "# Print the sheet names\n",
    "print(sheet_names)\n",
    "\n",
    "\n",
    "# specify the excel sheet name, if needed\n",
    "# sheet_name= \"sheet_names\"\n",
    "# Load the data from the  file into a DataFrame\n",
    "excel_data = pd.read_excel(latest_file, sheet_name= sheet_names[4] ,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we want combine the multiple sheets from the Excel file into dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of relevant sheets in Excel\n",
    "# 'Video Action Store Visit Report'\n",
    "# 'OTC Brand Store Report'\n",
    "# 'Pmax Store Report'\n",
    "# 'OTC NB Store Report'\n",
    "\n",
    "# list of relevant sheet names\n",
    "relevant_sheet_names = ['1d. Video Action Store Visit Re',\n",
    "'1c. OTC Brand Store Report',\n",
    "'1b . Pmax Store Report',\n",
    "'1a. OTC NB Store Report'    \n",
    "]\n",
    "\n",
    "# initialize an empty list to hold the data frames, sheets being combined\n",
    "list_dataframes = []\n",
    "\n",
    "# initalize a counter variable to hold the counts of total records for each sheet\n",
    "total_records = 0\n",
    "\n",
    "\n",
    "for sheet in relevant_sheet_names:\n",
    "    # load the data from the sheet into a dataframe\n",
    "    input_store_list_data= pd.read_excel(latest_file, sheet_name=sheet, header=1)\n",
    "    \n",
    "    \n",
    "    # Strip leading and trailing white spaces from column names\n",
    "    input_store_list_data.columns = input_store_list_data.columns.str.strip()\n",
    "    \n",
    "    # Standardize column names by removing white spaces\n",
    "    input_store_list_data.columns = input_store_list_data.columns.str.replace(' ', '_')\n",
    "    \n",
    "    # if the sheet is in the list we need to populated the missing column with nans\n",
    "    if sheet== \"1d. Video Action Store Visit Re\":\n",
    "        input_store_list_data[\"Location_city\"] = np.nan\n",
    "        # Check if \"Location address line 1\" column exists before trying to rename it\n",
    "        if \"Location_address_line_1\" in input_store_list_data.columns:\n",
    "            input_store_list_data.rename(columns={\"Location_address_line_1\":\"Location_address_line\"} , inplace=True)\n",
    "        \n",
    "    # Append each dataframe to the list\n",
    "    list_dataframes.append(input_store_list_data)\n",
    "    \n",
    "    # print the number of recoreds in the current sheet\n",
    "    print(f\"Number of records in the current {sheet}: {len(input_store_list_data)}\")\n",
    "    \n",
    "    # add the number of records in the current sheet to the total\n",
    "    total_records+= len(input_store_list_data)\n",
    "\n",
    "# concatenate all dataframes in the list into one    \n",
    "combined_df = pd.concat(list_dataframes, ignore_index=True)\n",
    "\n",
    "# print the total rcords in the combined dataframe\n",
    "\n",
    "print(f\"Total number of records in combined dataset {len(combined_df)}\")\n",
    "\n",
    "import itables\n",
    "itables.show(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into Pandas\n",
    "data = pd.read_csv('palm_springs_data.csv')\n",
    "\n",
    "# Set display options\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "#pd.set_option('display.precision', 2)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It helps to read in line-by-line using readlines before you specify\n",
    "# your arugments for pd.read_csv!\n",
    "# Why are we doing it this way?\n",
    "# This file is pretty small so we could just open it in notepad or whatnot\n",
    "# But what if...it wasn't?  Or we had many files just like this?\n",
    "# So this is an automated way to help us decide how many rows we will have to skip!\n",
    "i=0\n",
    "for line in (open(r'..\\Data\\co2_daily_mlo.txt').readlines()):\n",
    "    i = i+1\n",
    "    print(i,line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll want to skip rows INCLUDING the original column headings in the raw file as we are going to reset those\n",
    "# Via the names=[\"Year\", \"Month\", \"Day\", \"Decimal Date\", \"CO2\"] argument that you'll pass to read_csv\n",
    "# You'll also want to pass a special argument to read_csv so Pandas understands how to separate the columns, yes?\n",
    "csv_data = pd.read_csv(r'..\\Data\\co2_daily_mlo.txt',skiprows=67,sep=r'\\s+', names=[\"Year\", \"Month\", \"Day\", \"Decimal Date\", \"CO2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dedupe-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
